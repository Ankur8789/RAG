# ğŸ“š RAG Chatbot (Groq + Pinecone + HuggingFace + Streamlit)

A **Retrieval-Augmented Generation (RAG)** chatbot that lets you chat with your documents using:

- âš¡ **Groq** (fast, FREE LLM inference)
- ğŸ§  **HuggingFace Inference API** (FREE embeddings)
- ğŸ—‚ï¸ **Pinecone** (vector database)
- ğŸ”— **LangChain** (orchestration)
- ğŸ¨ **Streamlit** (UI)

This project avoids OpenAI entirely and runs fully on **free tiers**.

---

## ğŸš€ High-Level Architecture

User Query
â†“
HuggingFace Embeddings
â†“
Pinecone Vector Search
â†“
Relevant Chunks
â†“
Groq LLM
â†“
Final Answer

---

## ğŸ§± Tech Stack

| Layer        | Technology                                       |
| ------------ | ------------------------------------------------ |
| UI           | Streamlit                                        |
| Embeddings   | HuggingFace `mixedbread-ai/mxbai-embed-large-v1` |
| Vector Store | Pinecone                                         |
| LLM          | Groq (`openai/gpt-oss-120b`)                     |
| Framework    | LangChain                                        |
| Language     | Python 3.10+                                     |

---

## ğŸ“ Project Structure

RAG/
â”œâ”€â”€ chatbot/
â”‚ â””â”€â”€ chatbot.py
â”œâ”€â”€ ingestion.py
â”œâ”€â”€ documents/
â”‚ â””â”€â”€ \*.pdf
â”œâ”€â”€ venv/
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## ğŸ” Environment Variables (`.env`)

Create a `.env` file in the project root:

```env
# Pinecone
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX_NAME=le-beta-v2

# Groq
GROQ_API_KEY=your_groq_api_key

# HuggingFace (Embeddings)
EMBED_KEY=your_huggingface_read_token


ğŸ“¦ Install Dependencies
pip install -r requirements.txt

requirements.txt
streamlit
python-dotenv
pinecone-client
langchain
langchain-core
langchain-community
langchain-pinecone
langchain-groq
langchain-huggingface

ğŸŒ Service Setup
1ï¸âƒ£ Pinecone Setup

Go to https://www.pinecone.io

Create a Serverless Index

Set:

Dimension: 1024

Metric: cosine

Save the index name in .env

âš ï¸ Dimension must match mxbai-embed-large-v1

2ï¸âƒ£ Groq Setup (FREE LLM)

Go to https://console.groq.com

Create an API key

Supported models:

âœ… openai/gpt-oss-120b

âœ… llama3-8b-8192

âŒ llama3-70b-8192 (deprecated)

3ï¸âƒ£ HuggingFace Setup (FREE Embeddings)

Go to https://huggingface.co/settings/tokens

Create a Read-only token

Use it as EMBED_KEY

ğŸ“¥ Document Ingestion Flow
PDFs
 â†“
PyPDFDirectoryLoader
 â†“
LangChain Documents
 â†“
Text Splitter
 â†“
Embeddings
 â†“
Pinecone

Correct Import (LangChain v0.2+)
from langchain_community.document_loaders import PyPDFDirectoryLoader

â–¶ï¸ Run the Chatbot
streamlit run chatbot/chatbot.py

ğŸ§  RAG Prompt Strategy

The LLM is instructed to:

Use only retrieved context

Say "I don't know" if answer isnâ€™t in context

Answer in â‰¤ 3 sentences

ğŸ” Debugging & Observability

The app prints:

ğŸ” User query

ğŸ“„ Retrieved documents

ğŸ“Š Similarity scores

ğŸ§  Final system prompt

ğŸ¤– LLM response

This helps debug semantic search quality.
```
